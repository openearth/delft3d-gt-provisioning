#!/usr/bin/env bash

# by default we're not on amazon
# See, also for alternatives
# http://serverfault.com/questions/462903/how-to-know-if-a-machine-is-an-ec2-instance
EC2=0
if [ -f /sys/hypervisor/uuid ] && [ $(head -c 3 /sys/hypervisor/uuid) == "ec2" ]; then
    # introspect the machine
    EC2=1
fi

# Amazon specific code goes here
if [ "$EC2" == "1" ]
then
    if [ -z "$uuid" ]
    then
        echo "Failed to find $uuid on amazon, not sure where to put my files"
        echo "Make sure you set the uuid"
        exit 1
    fi

    # check in arguments what to do.
    # cleanup -> synchronize files to S3 bucket and remove files from EFS
    # rerun -> synchronize simulation files from S3 to EFS
    for argument in $@; do
        if [ "$argument" == "cleanup" ]
        then
            # write tree log of the EFS directory
            ls -lhR /data/input/ > /data/input/EFStree.log

            # caputer number of files in the EFS directory 
            I="$(find . -type f | wc -l)"

            # write tree log of the S3 directory
            aws s3 ls  "s3://{{ bucket }}/data/container/files/$uuid" --recursive --summarize > /data/input/S3tree.log

            # capture number of files in the S3 directory
            J="$(grep  "^Total Objects:" /data/input/S3tree.log | grep -Eo "[0-9]+")"

            # synchronize directory with on s3 (make sure you provision aws command lines (pip install aws-cli))
            aws s3 sync /data/input/ "s3://{{ bucket }}/data/container/files/$uuid" --exact-time

            # Capture sync status
            SYNC_STATUS=$?

            if ["$I" == "$J"] && ["$SYNC_STATUS" == "0"];
            then
                echo "start cleanup"
                rm -rf /data/input/*
                echo "All directories are removed"
            else
                echo "Didn't clean EFS directories"
                echo "Number of files in EFS directory: $I"
                echo "Number of files in S3 directory: $J"
                echo "SYNC_STATUS: $SYNC_STATUS"
            fi

        elif [ "$argument" == "rerun" ]
        then
            # remove old backups
            aws s3 rm "s3://{{ bucket }}/data/container/files/$uuid/backup/" --recursive
            # backup the old output except the simulation folder
            aws s3 cp "s3://{{ bucket }}/data/container/files/$uuid/" "s3://{{ bucket }}/data/container/files/$uuid/backup/" --exclude "simulation/*" --exclude "backup/*" --recursive
            # synchronize simulation folder from s3 back to the Elastic File System. Exclude ini file, this file is generated in do_docker_create task.
            echo "sync S3 to EFS"
            aws s3 sync "s3://{{ bucket }}/data/container/files/$uuid/simulation" /data/output/simulation --exclude "input.ini" --exact-time
        fi
    done
fi

